{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final \n",
    "\n",
    "_Fecha: 16 de mayo 2019_\n",
    "\n",
    "Enviar un enlace a un repositorio de GitHub que contenga los trabajos realizados durante el semestre, la carpeta debe contener las siguientes entregas:\n",
    "\n",
    "+ MNIST (digitos) con algoritmo deterministico\n",
    "+ Tic-tac-toe\n",
    "+ Sistema experto\n",
    "+ Opcional (Artificial Life)\n",
    "+ MNIST (digitos) machine learning - Kmeans\n",
    "+ MNIST (digitos) deep learning, Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (dígitos) deep learning, Tensorflow\n",
    "\n",
    "__Integrantes:__\n",
    "\n",
    "+ Nombre: **Brayan G. Bejarano**\n",
    "+ Nombre: **Bayron Campaz**\n",
    "\n",
    "\n",
    "Entrenar una red neuronal con el fin de detectar los dígitos de MNIST y comparar sus resultados contra el algoritmo determinístico y el modelo de machine learning kmeans.\n",
    "\n",
    "Evaluar los resultados contra dos medidas de evaluación (accuracy y tiempo de entramiento). Se recomienda realizar el hold-out con un 80% para entrenamiento y un conjunto de testeo del 20%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación contra el mejor modelo TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente es una implementacion con TensorFlow para la prediccion de numeros como un conjunto de imagenes. Esta implementacion consiste en una red neuronal con dos capas ocultas y optimizada de tal forma que permitiese generar los mejores resultados en el menor tiempo posible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-79252d13122b>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Read data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weigth_shape, bias_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev= (2.0/weigth_shape[0]) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weigth_shape, initializer = w_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer = bias_init)\n",
    "    return tf.nn.relu(tf.matmul(input, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan las capas ocultas y la capa de salida, utilizamos 2 capas ocultas para mayor precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):     \n",
    "    with tf.variable_scope(\"hidden_1\"):\n",
    "        hidden_1 = layer(x , [784, 256], [256])\n",
    "    with tf.variable_scope(\"hidden_2\"):\n",
    "        hidden_2 = layer(hidden_1, [256, 256], [256])\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_2, [256, 10], [10])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos algunos metodos para la aproximacion por regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"validation\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos al algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se despliega todo el proceso de entrenamiento con tensorflow usando un learning rate del 0.01 y 30 epocas de entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: 0.09839999675750732\n",
      "Validation Error: 0.042999982833862305\n",
      "Validation Error: 0.03240001201629639\n",
      "Validation Error: 0.02679997682571411\n",
      "Optimization Finished!\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "# Parameters\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 10\n",
    "display_step = 5\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # mnist data image of shape 28*28=784\n",
    "    x = tf.placeholder(tf.float32, [None, 784])    \n",
    "    # 0-9 digits recognition => 10 classes\n",
    "    y = tf.placeholder(tf.float32, [None, 10])    \n",
    "    output = inference(x)    \n",
    "    cost = loss(output, y) \n",
    "    \n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)    \n",
    "    train_op = training(cost, global_step)    \n",
    "    eval_op = evaluate(output, y)\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    sess = tf.Session()    \n",
    "    summary_writer = tf.summary.FileWriter(\"mnist_logs/\", graph=sess.graph)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = 1440 #Este es el número de casos que se usa n el entrenamiento de todos los metodos\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            mbatch_x, mbatch_y = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            feed_dict = {x : mbatch_x, y : mbatch_y}\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            # Compute average loss\n",
    "            minibatch_cost = sess.run(cost, feed_dict=feed_dict)\n",
    "            avg_cost += minibatch_cost/total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            val_feed_dict = {\n",
    "                x : mnist.validation.images,\n",
    "                y : mnist.validation.labels\n",
    "            }\n",
    "            accuracy = sess.run(eval_op, feed_dict=val_feed_dict)\n",
    "            print (\"Validation Error:\", (1 - accuracy))\n",
    "            train_losses.append(1 - accuracy)\n",
    "            summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "            summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "            \n",
    "            saver.save(sess, \"mnist_logs/model-checkpoint\", global_step=global_step)\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se hace el test de lmodelo anteriormente entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "    test_feed_dict = {\n",
    "        x : mnist.test.images,\n",
    "        y : mnist.test.labels\n",
    "    }\n",
    "    accuracy = sess.run(eval_op, feed_dict=test_feed_dict)\n",
    "    print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa se tiene una precision de alrededor de 97.6% la cual es bastante alta, eso si luego de que  el modelo estuviese alrededor de 2 minutos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación contra el mejor modelo KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente es una implementacion que usa el algoritmo KNN desde la libreria sklearn para la prediccion de numeros como un conjunto de imagenes.\n",
    "\n",
    "Este algoritmo se basa en crear una base de conocimiento basada en clasificación en la fase de entrenamiento para posteriormente en la fase de predicción buscar las observaciones mas cercanas a las que esta tratando de predecir y clasifica el punto de interés basado en la mayoría de datos que le rodean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import sklearn.metrics as metrics\n",
    "import pylab as pl\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes lineas se hace la division del conjunto de datos con un porcentaje del 80% para entrenamiento y un 20% para pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "percentFit = 0.8\n",
    "numImagenes = len(digits.images)\n",
    "limitInferior =  math.floor(numImagenes*percentFit)+1\n",
    "limitSuperior = math.ceil(numImagenes*percentFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target[0 : limitInferior] # El método nos provee las etiquetas de las imágenes en un arreglo\n",
    "w = digits.target[limitSuperior :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar la representación de los datos, se aplana las matrices de pixeles para poner cada imagen en un solo array de 64 pixeles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.images[0 : limitInferior].reshape((len(y), -1)) # Se selecciona el porcentaje de entrenamiento.\n",
    "Z = digits.images[limitSuperior :].reshape((len(w),-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa las librerias correspondientes a KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn = KNeighborsClassifier(4)\n",
    "fit = knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego procedemos a estimar con el conjuto de datos destinado para tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_estimado = fit.predict(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente calculamos la eficacia del algoritma lo cual nos da:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665738161559888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(w, w_estimado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior indica que el algoritmo KNN con los datos de entrenamiento brindados y 4 nodos predice el numero correctamente con un 96,6% de efectividad, lo que se puede considerar como un valor bastante alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación contra el resultado del algoritmo deterministico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para el 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene los digitos y se almacenan en un arreglo los indices en el que el número objetivo es igual a 4 y reciprocamente se almacenan en otro arreglo los que son diferentes de 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 14, 24, 41, 64, 68, 87, 97, 100, 110, 111, 121, 124, 134, 144, 154, 171, 194, 198, 225, 228, 238, 239, 247, 250, 260, 270, 280, 297, 320, 324, 343, 353, 356, 366, 367, 377, 380, 390, 400, 410, 427, 450, 454, 473, 483, 486, 496, 497, 507, 510, 520, 530, 540, 557, 580, 584, 603, 613, 616, 626, 627, 637, 640, 650, 660, 670, 687, 710, 714, 733, 743, 746, 756, 757, 767, 770, 780, 790, 800, 817, 840, 844, 863, 873, 876, 886, 887, 897, 900, 909, 919, 929, 946, 966, 970, 988, 998, 1001, 1011, 1012, 1022, 1023, 1033, 1043, 1053, 1070, 1091, 1095, 1114, 1124, 1127, 1137, 1138, 1148, 1151, 1161, 1171, 1181, 1198, 1221, 1225, 1244, 1254, 1257, 1267, 1268, 1278, 1281, 1291, 1301, 1311, 1328, 1351, 1355, 1374, 1384, 1387, 1397, 1398, 1408, 1411, 1419, 1429, 1439, 1456, 1479, 1483, 1502, 1512, 1515, 1525, 1526, 1536, 1539, 1549, 1559, 1567, 1584, 1607, 1611, 1628, 1638, 1641, 1651, 1652, 1660, 1661, 1671, 1681, 1691, 1708, 1731, 1735, 1754, 1764, 1767, 1777, 1778, 1788, 1791]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import sklearn.metrics as metrics\n",
    "import pylab as pl\n",
    "import sklearn\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "theFours = []\n",
    "theNotFours = []\n",
    "i: int = 0\n",
    "numFours: int = 0\n",
    "     \n",
    "while i < len(digits.target):\n",
    "    if digits.target[i] == 4:\n",
    "        theFours.append(i)\n",
    "        numFours = numFours + 1\n",
    "    else:\n",
    "        theNotFours.append(i)\n",
    "    i = i + 1\n",
    "print(theFours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente metodo contiene las reglas y retricciones que determinan si la matriz de entrada representa un 4. Devuelve un valor booleano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace un analisis y se encuentra que existe un patrón de \"casillas\" con \n",
    "#valores altos, la estrategia consiste en verificar que el valor de la matriz de entrada en esa casilla\n",
    "#este en un rango definido heuristicamente\n",
    "def is_the_number_four(numIn):\n",
    "    numImage = digits.images[numIn]\n",
    "    isFour: bool = True\n",
    "    hasBase: bool = True\n",
    "    x: int = 5\n",
    "    y: int = 3\n",
    "    while x < 8 and hasBase:       \n",
    "        if numImage[x][y] < 10:\n",
    "            y = y + 1\n",
    "            x = 5\n",
    "            if y == 6:\n",
    "                hasBase = False\n",
    "        else:           \n",
    "            x = x + 1\n",
    "    \n",
    "    hasLateral: bool = False\n",
    "        \n",
    "    if hasBase:\n",
    "        if numImage[5][y - 1] > 8 or numImage[5][y + 1] > 8 :\n",
    "            if numImage[4][y - 1] > 8 or numImage[4][y + 1] > 8:\n",
    "                hasLateral = True\n",
    "            else:\n",
    "                isFour = False\n",
    "        else:\n",
    "            isFour = False\n",
    "    else:\n",
    "        isFour = False\n",
    "    \n",
    "    if isFour and hasBase and hasLateral:\n",
    "        if numImage[0][3] < 9 and numImage[0][4] < 9 and numImage[0][5]:\n",
    "            isFour = False\n",
    "\n",
    "    return isFour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace iteracion sobre los arreglos de las matrices de numeros para que el anterior algoritmo decida si el número es correcto, y se devuelve la eficiencia del algoritmo. Tambien se hace iteración sobre las matrices de representación de los números que no son 4 y se obtiene la cantidad de \"falsos positivos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficacia\n",
      "0.8176795580110497\n",
      " \n",
      "Falsos Positivos\n",
      "0.28960396039603964\n",
      "Wall time: 13.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "numTrues: int = 0\n",
    "numFalses: int = 0\n",
    "    \n",
    "for num in theFours: \n",
    "    if is_the_number_four(num)==True:\n",
    "        numTrues = numTrues + 1\n",
    "\n",
    "for num in theNotFours:\n",
    "    if not is_the_number_four(num)==True:\n",
    "        numFalses = numFalses + 1\n",
    "print(\"Eficacia\")        \n",
    "print(numTrues/len(theFours))\n",
    "print(\" \")\n",
    "print(\"Falsos Positivos\")   \n",
    "print(1 - (numFalses/len(theNotFours)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para el 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eficiencia\n",
      "74.03314917127072\n",
      " \n",
      "Falsos Positivos\n",
      "0.0\n",
      "Wall time: 39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "contador = 0\n",
    "uno = 0\n",
    "seis = 1797\n",
    "\n",
    "for i in range(1797):\n",
    "    matriz = digits.images[i]\n",
    "    for j in range(5,7):\n",
    "        for k in range(0,3):\n",
    "            if(matriz[j][k] > 10):\n",
    "                contador+= 1\n",
    "                break\n",
    "                \n",
    "for i in range(1797):\n",
    "    matriz = digits.images[i]\n",
    "    for j in range(1):\n",
    "        for k in range(3):\n",
    "            if(matriz[j][k] > 10):\n",
    "                uno+= 1\n",
    "                break\n",
    "                \n",
    "contador += uno\n",
    "seis -= contador\n",
    "accuracy = ((8*8*seis)/(8*8*181))*100\n",
    "\n",
    "print(\"Eficiencia\")\n",
    "print(accuracy)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Falsos Positivos\") \n",
    "print(\"0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el entrenamiento del algoritmo es empirico dado que se determina por los patrones que identificamos en las matrices de los numeros correspondientes a los numeros 4 y 6 por lo que en este caso el tiempo de entrenamiento es el tiempo que tomamos para realizar estos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones Finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede notar como el modelo deterministico es mucho mas impreciso que el de KNN o el de redes neuronales al tener en promedio 77.9% de eficacia frente al 96.6% y 97.2% de estos dos ultimos respectivamente. Con esto podemos afirmar que la mejor opción de las tres es el método de redes neuronales siempre y cuando se cuente con una capacidad de computo alta, en caso cotrario el mejor metodo sería la clasificación supervisada de KNN o vecinos cercanos, ya que a pesar de que el metodo de redes neuronales es más preciso, el entrenamiento toma mucho mas tiempo en este metodo lo que hace que sea mucho mas efectivo el KNN, el cual tiene una precision similar a la de las redes neuronales pero con la gran ventaja de tener un tiempo de entrenamiento mucho mas corto que este ultimo. \n",
    "\n",
    "Cabe aclarar que aunque para este problema el KNN sea mas efectivo (entendiendo efectividad como la suma de precision y eficacia) las redes neuronales son mucho más manipulables al involucrar muchos más parametros para la realizacion del entrenamiento como lo son el learning rate, la cantidad de neuronas a usar, la función de activación e incluso las epocas de entrenamiento lo que hace de esta una herramienta poderosa en cuanto machine learning se refiere, dando la posibilidad de tener casi infinitas combinaciones a la hora de resolver un problema de clasificación.\n",
    "\n",
    "Finalmente podemos afirmar que la mayoria de problemas relacionados con machine learning se pueden resolver escogiendo el metodo que mas se acomode al problema, buscando librerias que ya implementen estos metodos y primordialmente entendiendo como estos funcionan y que parametros se pueden controlar para obtener mayor provecho de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
